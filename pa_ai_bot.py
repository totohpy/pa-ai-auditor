# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import os
import io
# *** ‡πÄ‡∏û‡∏¥‡πà‡∏° Imports ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG Chatbot ***
from PyPDF2 import PdfReader
import glob
from io import StringIO

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG
DOC_FOLDER = "Doc" 
MAX_CHARS_LIMIT = 100000 # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà 100,000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏à
st.set_page_config(page_title="Planning Studio (+ PA Assistant)", page_icon="üß≠", layout="wide")

# ----------------- Utility Functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG Chatbot -----------------

def read_pdf_text_from_path(file_path):
    """Extracts text content from a PDF file using a local file path."""
    try:
        with open(file_path, 'rb') as file:
            reader = PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() or ""
            return text
    except Exception:
        return ""

def read_pdf_text_from_uploaded(uploaded_file):
    """Extracts text content from an uploaded PDF file."""
    try:
        reader = PdfReader(uploaded_file)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
            return text
    except Exception:
        return ""
    
def get_text_from_file(file, source_type):
    """Handles text extraction based on file source (local path or uploaded object)."""
    file_name = file if source_type == 'local' else file.name
    file_extension = os.path.splitext(file_name)[1].lower()
    current_text = ""
    
    try:
        if file_extension == '.pdf':
            if source_type == 'local':
                current_text = read_pdf_text_from_path(file)
            else:
                current_text = read_pdf_text_from_uploaded(file)
        elif file_extension == '.txt':
            if source_type == 'local':
                with open(file, 'r', encoding='utf-8') as f:
                    current_text = f.read()
            else:
                current_text = StringIO(file.getvalue().decode("utf-8")).read()
        elif file_extension == '.csv':
            if source_type == 'local':
                try:
                    df = pd.read_csv(file, encoding='utf-8')
                except UnicodeDecodeError:
                    df = pd.read_csv(file, encoding='TIS-620')
            else:
                try:
                    df = pd.read_csv(file, encoding='utf-8')
                except UnicodeDecodeError:
                    df = pd.read_csv(file, encoding='TIS-620')

            current_text = df.to_string()
    
    except Exception as e:
        return "", ""

    return current_text, file_name


def process_documents(files, source_type, max_chars_limit, existing_context_len):
    """
    Processes a list of files (either local paths or uploaded objects) and returns context.
    *** ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (TRUNCATION) ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô MAX_CHARS_LIMIT ***
    """
    context = ""
    total_chars = existing_context_len
    
    for file in files:
        current_text, file_name = get_text_from_file(file, source_type)
        
        if current_text:
            if total_chars + len(current_text) > max_chars_limit:
                remaining_chars = max_chars_limit - total_chars
                
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏¢‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏á (remaining_chars > 0) ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏°‡∏≤‡πÅ‡∏Ñ‡πà‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
                if remaining_chars > 0:
                    context += f"\n--- Start of Document: {file_name} (TRUNCATED) ---\n"
                    context += current_text[:remaining_chars] + f"\n... [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô‡∏à‡∏≤‡∏Å {file_name}]"
                    total_chars += remaining_chars
                
                break # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
            
            else:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏â‡∏ö‡∏±‡∏ö
                context += f"\n--- Start of Document: {file_name} ---\n"
                context += current_text
                context += f"\n--- End of Document: {file_name} ---\n"
                total_chars += len(current_text)
                if source_type == 'local':
                    st.toast(f"‡πÇ‡∏´‡∏•‡∏î: {file_name} ({len(current_text):,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)")
                else:
                    st.toast(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {file_name} ({len(current_text):,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)")

    return context, total_chars - existing_context_len

def load_local_documents_on_init():
    """Initial load function for Doc folder (run once)."""
    supported_files = []
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Doc ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not os.path.exists(DOC_FOLDER):
        os.makedirs(DOC_FOLDER)
    
    for ext in ['*.pdf', '*.txt', '*.csv']:
        supported_files.extend(glob.glob(os.path.join(DOC_FOLDER, ext)))
        
    if not supported_files:
        return ""

    context, total_chars_added = process_documents(supported_files, 'local', MAX_CHARS_LIMIT, 0)
    return context

# ----------------- Session Init (‡∏£‡∏ß‡∏° RAG State & Global API Key) -----------------
def init_state():
    ss = st.session_state
    ss.setdefault("plan", {
        "plan_id": "PLN-" + datetime.now().strftime("%y%m%d-%H%M%S"),
        "plan_title": "",
        "program_name": "",
        "who": "", "what": "", "where": "", "when": "", "why": "", "how": "", "how_much": "", "whom": "",
        "objectives": "", "scope": "", "assumptions": "", "status": "Draft"
    })
    ss.setdefault("logic_items", pd.DataFrame(columns=["item_id","plan_id","type","description","metric","unit","target","source"]))
    ss.setdefault("methods", pd.DataFrame(columns=["method_id","plan_id","type","tool_ref","sampling","questions","linked_issue","data_source","frequency"]))
    ss.setdefault("kpis", pd.DataFrame(columns=["kpi_id","plan_id","level","name","formula","numerator","denominator","unit","baseline","target","frequency","data_source","quality_requirements"]))
    ss.setdefault("risks", pd.DataFrame(columns=["risk_id","plan_id","description","category","likelihood","impact","mitigation","hypothesis"]))
    ss.setdefault("audit_issues", pd.DataFrame(columns=["issue_id","plan_id","title","rationale","linked_kpi","proposed_methods","source_finding_id","issue_detail", "recommendation"]))
    ss.setdefault("gen_issues", "")
    ss.setdefault("gen_findings", "")
    ss.setdefault("gen_report", "")
    ss.setdefault("issue_results", pd.DataFrame())
    ss.setdefault("ref_seed", "") 
    ss.setdefault("issue_query_text", "")
    
    # *** GLOBAL API Key for all LLM features ***
    # ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å st.secrets ‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á
    ss.setdefault("api_key_global", st.secrets.get('OPENAI_API_KEY', '')) 
    
    # *** RAG Chatbot specific states ***
    ss.setdefault("doc_context_local", "") 
    ss.setdefault("doc_context_uploaded", "") 
    ss.setdefault("last_uploaded_files", set()) # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    ss.setdefault("chatbot_messages", [
        {"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (PA Assistant) ‡∏ú‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö"}
    ])
    ss.setdefault("local_load_attempted", False)
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° state ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ó‡πá‡∏ö‡πÑ‡∏´‡∏ô‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏¢‡∏π‡πà
    ss.setdefault("current_tab", "1. ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H")


def next_id(prefix, df, col):
    if df.empty: return f"{prefix}-001"
    nums = []
    for x in df[col]:
        try:
            nums.append(int(str(x).split("-")[-1]))
        except:
            pass
    n = max(nums) + 1 if nums else 1
    return f"{prefix}-{n:03d}"

def df_download_link(df: pd.DataFrame, filename: str, label: str):
    buf = BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button(label, data=buf.getvalue(), file_name=filename, mime="text/csv")

# ----------------- Findings Loader & Search -----------------
@st.cache_data(show_spinner=False)
def load_findings(uploaded=None):
    findings_df = pd.DataFrame()

    findings_db_path = "FindingsLibrary.csv"
    if os.path.exists(findings_db_path):
        try:
            findings_df = pd.read_csv(findings_db_path)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå FindingsLibrary.csv: {e}")
            findings_df = pd.DataFrame()

    if uploaded is not None:
        try:
            if uploaded.name.endswith('.csv'):
                uploaded_df = pd.read_csv(uploaded)
            elif uploaded.name.endswith(('.xlsx', '.xls')):
                xls = pd.ExcelFile(uploaded)
                if "Data" in xls.sheet_names:
                    uploaded_df = pd.read_excel(xls, sheet_name="Data")
                    st.success("‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ä‡∏µ‡∏ï 'Data' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                else:
                    st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏µ‡∏ï‡∏ä‡∏∑‡πà‡∏≠ 'Data' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡∏à‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏ä‡∏µ‡∏ï‡πÅ‡∏£‡∏Å‡πÅ‡∏ó‡∏ô")
                    uploaded_df = pd.read_excel(xls, sheet_name=0)

            if not uploaded_df.empty:
                findings_df = pd.concat([findings_df, uploaded_df], ignore_index=True)
                st.success(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå '{uploaded.name}' ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏•‡πâ‡∏ß")
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {e}")

    if not findings_df.empty:
        for c in ["issue_title","issue_detail","cause_detail","recommendation","program","unit"]:
            if c in findings_df.columns:
                findings_df[c] = findings_df[c].fillna("")
        if "year" in findings_df.columns:
            findings_df["year"] = pd.to_numeric(findings_df["year"], errors="coerce").fillna(0).astype(int)
        if "severity" in findings_df.columns:
            findings_df["severity"] = pd.to_numeric(findings_df["severity"], errors="coerce").fillna(3).clip(1,5).astype(int)

    return findings_df

@st.cache_resource(show_spinner=False)
def build_tfidf_index(findings_df: pd.DataFrame):
    texts = (findings_df["issue_title"].fillna("") + " " +
             findings_df["issue_detail"].fillna("") + " " +
             findings_df["cause_detail"].fillna("") + " " +
             findings_df["recommendation"].fillna(""))
    vec = TfidfVectorizer(max_features=20000, ngram_range=(1,2))
    X = vec.fit_transform(texts)
    return vec, X

def search_candidates(query_text, findings_df, vec, X, top_k=8):
    qv = vec.transform([query_text])
    sims = cosine_similarity(qv, X)[0]
    out = findings_df.copy()
    out["sim_score"] = sims
    if "year" in out.columns and out["year"].max() != out["year"].min():
        out["year_norm"] = (out["year"] - out["year"].min()) / (out["year"].max() - out["year"].min())
    else:
        out["year_norm"] = 0.0
    out["sev_norm"] = out.get("severity", 3) / 5
    out["score"] = out["sim_score"]*0.65 + out["sev_norm"]*0.25 + out["year_norm"]*0.10
    cols = [
        "finding_id","year","unit","program","issue_title","issue_detail",
        "cause_category","cause_detail","recommendation","outcomes_impact","severity","score"
    ]
    cols = [c for c in cols if c in out.columns] + ["sim_score"]
    return out.sort_values("score", ascending=False).head(top_k)[cols]
    
def create_excel_template():
    df = pd.DataFrame(columns=[
        "finding_id", "issue_title", "unit", "program", "year", 
        "cause_category", "cause_detail", "issue_detail", "recommendation", 
        "outcomes_impact", "severity"
    ])
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='FindingsLibrary')
    processed_data = output.getvalue()
    return processed_data

# ----------------- App UI -----------------
init_state()

# *** Initial Load RAG Data ***
if not st.session_state.doc_context_local and not st.session_state.get('local_load_attempted', False):
    st.session_state.doc_context_local = load_local_documents_on_init()
    st.session_state.local_load_attempted = True
# *****************************

plan = st.session_state["plan"]
logic_df = st.session_state["logic_items"]
methods_df = st.session_state["methods"]
kpis_df = st.session_state["kpis"]
risks_df = st.session_state["risks"]
audit_issues_df = st.session_state["audit_issues"]

st.title("üß≠ Planning Studio ‚Äì Performance Audit")

# ----------------- START: Custom CSS (User's preferred multi-color tabs) -----------------
st.markdown("""
<style>
/* ... (Custom CSS ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏µ‡πÅ‡∏ó‡πá‡∏ö‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ... */
/* ---- Global Font ---- */
body { font-family: 'Kanit', sans-serif; }

/* ---- Base Style for Tabs (Button Look) ---- */
button[data-baseweb="tab"] {
    border: 1px solid #007bff;
    border-radius: 8px;
    padding: 10px 15px;
    margin: 5px 5px 5px 0px;
    transition: background-color 0.3s, color 0.3s;
    font-weight: bold;
    color: #007bff !important;
    background-color: #ffffff;
    box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);
    /* Remove default Streamlit tab line/highlight */
    border-bottom: none !important; 
    &::after { content: none !important; }
}
button[data-baseweb="tab"][aria-selected="true"] {
    box-shadow: 2px 2px 5px rgba(0,0,0,0.2);
}

/* ---- Group 1: 1-5 (Blue - Planning) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(1),
div[data-baseweb="tab-list"] button:nth-of-type(2),
div[data-baseweb="tab-list"] button:nth-of-type(3),
div[data-baseweb="tab-list"] button:nth-of-type(4),
div[data-baseweb="tab-list"] button:nth-of-type(5) {
    border-color: #007bff;
    color: #007bff !important;
}
div[data-baseweb="tab-list"] button:nth-of-type(1)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(2)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(3)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(4)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(5)[aria-selected="true"] {
    background-color: #007bff;
    color: white !important;
}

/* ---- Group 2: 6-7 (Purple - Analysis/Review) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(6),
div[data-baseweb="tab-list"] button:nth-of-type(7) {
    border-color: #6f42c1;
    color: #6f42c1 !important;
}
div[data-baseweb="tab-list"] button:nth-of-type(6)[aria-selected="true"],
div[data-baseweb="tab-list"] button:nth-of-type(7)[aria-selected="true"] {
    background-color: #6f42c1;
    color: white !important;
}

/* ---- Group 3: 8 (Gold - AI/Assist) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(8) {
    border-color: #ffc107;
    color: #cc9900 !important;
    box-shadow: 0 0 5px rgba(255, 193, 7, 0.5);
}
div[data-baseweb="tab-list"] button:nth-of-type(8)[aria-selected="true"] {
    background-color: #ffc107;
    border-color: #ffc107;
    color: #333333 !important;
}

/* ---- Group 4: 9 (Green - Chatbot) ---- */
div[data-baseweb="tab-list"] button:nth-of-type(9) {
    border-color: #28a745;
    color: #28a745 !important;
    box-shadow: 0 0 5px rgba(40, 167, 69, 0.5);
}
div[data-baseweb="tab-list"] button:nth-of-type(9)[aria-selected="true"] {
    background-color: #28a745;
    border-color: #28a745;
    color: white !important;
}

/* ---- Container/Layout/Responsiveness ---- */
div[data-baseweb="tab-list"] { border-bottom: none !important; margin-bottom: 15px; flex-wrap: wrap; gap: 10px; }
@media (max-width: 768px) {
    .st-emotion-cache-18ni2cb, .st-emotion-cache-1jm69l4, [data-testid="stColumn"] {
        width: 100% !important;
        margin-bottom: 1rem;
    }
}

/* ---- Headers ---- */
h4 { color: #007bff !important; border-bottom: 2px solid #e0e0e0; padding-bottom: 5px; }

/* *** CSS FIX: Chat Input Alignment *** */
/* Fix st.chat_input alignment/width issue in wide layout by forcing full width */
div[data-testid="stForm"] {
    width: 100% !important;
    max-width: 100% !important;
}
div[data-testid="stChatInput"] {
    width: 100% !important;
    max-width: 100% !important;
}
</style>
""", unsafe_allow_html=True)
# ----------------- END: Custom CSS -----------------

# ----------------- Tab Definitions (‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ó‡πá‡∏ö‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß) -----------------
# ‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô on_click ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏ó‡πá‡∏ö‡πÑ‡∏´‡∏ô
def set_current_tab(tab_name):
    st.session_state.current_tab = tab_name

tab_plan, tab_logic, tab_method, tab_kpi, tab_risk, tab_issue, tab_preview, tab_assist, tab_chatbot = st.tabs([
    "1. ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H", 
    "2. ‡∏£‡∏∞‡∏ö‡∏∏ Logic Model", 
    "3. ‡∏£‡∏∞‡∏ö‡∏∏ Methods", 
    "4. ‡∏£‡∏∞‡∏ö‡∏∏ KPIs", 
    "5. ‡∏£‡∏∞‡∏ö‡∏∏ Risks", 
    "6. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤", 
    "7. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview)", 
    "üí° Assistant ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö", 
    "üí¨ PA Chat (‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡πÄ)"
]) 

# ----------------- Tab 1: ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H -----------------
with tab_plan:
    set_current_tab("1. ‡∏£‡∏∞‡∏ö‡∏∏ ‡πÅ‡∏ú‡∏ô & 6W2H")
    # ... (‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á Tab 1) ...
    st.subheader("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô (Plan) - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    with st.container(border=True):
        c1, c2, c3 = st.columns([2,2,1])
        with c1:
            plan["plan_title"] = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ú‡∏ô/‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à", plan["plan_title"])
            plan["program_name"] = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô", plan["program_name"])
            plan["objectives"] = st.text_area("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["objectives"])
        with c2:
            plan["scope"] = st.text_area("‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à", plan["scope"])
            plan["assumptions"] = st.text_area("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", plan["assumptions"])
        with c3:
            st.text_input("Plan ID", plan["plan_id"], disabled=True)
            plan["status"] = st.selectbox("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", ["Draft","Published"], index=0)

    st.divider()
    st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (6W2H)")

    def save_api_key_global():
        st.session_state.api_key_global = st.session_state.api_key_input_6w2h

    with st.expander("üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢ AI (‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î)"): 
        with st.container(border=True):
            st.write("‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≥‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ")
            uploaded_text = st.text_area("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ 6W2H", height=200, key="uploaded_text")
            
            st.markdown("üí° **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ API Key?** ‡∏Ñ‡∏•‡∏¥‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://playground.opentyphoon.ai/settings/api-key) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö key ‡∏ü‡∏£‡∏µ!")
            api_key_6w2h = st.text_input(
                "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ AI:", 
                type="password", 
                value=st.session_state.api_key_global,
                key="api_key_input_6w2h",
                on_change=save_api_key_global
            )
            api_key_6w2h = st.session_state.api_key_global
            
            if st.button("üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°", type="primary", key="6w2h_button"):
                if not uploaded_text:
                    st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô")
                elif not api_key_6w2h:
                    st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
                else:
                    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                        try:
                            user_prompt = f"""
‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 6W2H ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà Who, Whom, What, Where, When, Why, How, ‡πÅ‡∏•‡∏∞ How much ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö key-value ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:
---
{uploaded_text}
---
‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
Who: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
Whom: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
What: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
Where: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
When: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
Why: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
How: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
How Much: [‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°]
"""
                            client = OpenAI(
                                api_key=api_key_6w2h,
                                base_url="https://api.opentyphoon.ai/v1"
                            )
                            response = client.chat.completions.create(
                                model="typhoon-v2.1-12b-instruct",
                                messages=[{"role": "user", "content": user_prompt}],
                                temperature=0.7,
                                max_tokens=1024,
                                top_p=0.9,
                            )
                            llm_output = response.choices[0].message.content
                            
                            with st.expander("‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å AI"):
                                st.write(llm_output)

                            lines = llm_output.strip().split('\n')
                            for line in lines:
                                if ':' in line:
                                    key, value = line.split(':', 1)
                                    normalized_key = key.strip().lower().replace(' ', '_')
                                    value = value.strip()
                                    if normalized_key == 'how_much': st.session_state.plan['how_much'] = value
                                    elif normalized_key == 'whom': st.session_state.plan['whom'] = value
                                    elif normalized_key == 'who': st.session_state.plan['who'] = value
                                    elif normalized_key == 'what': st.session_state.plan['what'] = value
                                    elif normalized_key == 'where': st.session_state.plan['where'] = value
                                    elif normalized_key == 'when': st.session_state.plan['when'] = value
                                    elif normalized_key == 'why': st.session_state.plan['why'] = value
                                    elif normalized_key == 'how': st.session_state.plan['how'] = value

                            st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á 6W2H ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÑ‡∏õ‡∏ß‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")
                            st.balloons()
                        except Exception as e:
                            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ AI: {e}")
    # *** END: ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏Å‡∏ï‡∏≤ - ‡∏ã‡πà‡∏≠‡∏ô‡∏™‡πà‡∏ß‡∏ô AI Assist ‡∏î‡πâ‡∏ß‡∏¢ expander ***
        
    st.markdown("##### ‚≠ê‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
    with st.container(border=True):
        cc1, cc2, cc3 = st.columns(3)
        with cc1:
            st.session_state.plan["who"] = st.text_input("Who (‡πÉ‡∏Ñ‡∏£)", value=st.session_state.plan["who"], key="who_input")
            st.session_state.plan["whom"] = st.text_input("Whom (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏Ñ‡∏£)", value=st.session_state.plan["whom"], key="whom_input")
            st.session_state.plan["what"] = st.text_input("What (‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£)", value=st.session_state.plan["what"], key="what_input")
            st.session_state.plan["where"] = st.text_input("Where (‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô)", value=st.session_state.plan["where"], key="where_input")
        with cc2:
            st.session_state.plan["when"] = st.text_input("When (‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î)", value=st.session_state.plan["when"], key="when_input")
            st.session_state.plan["why"] = st.text_area("Why (‡∏ó‡∏≥‡πÑ‡∏°)", value=st.session_state.plan["why"], key="why_input")
        with cc3:
            st.session_state.plan["how"] = st.text_area("How (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£)", value=st.session_state.plan["how"], key="how_input")
            st.session_state.plan["how_much"] = st.text_input("How much (‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£)", value=st.session_state.plan["how_much"], key="how_much_input")

# ----------------- Tab 2: Logic Model -----------------
with tab_logic:
    set_current_tab("2. ‡∏£‡∏∞‡∏ö‡∏∏ Logic Model")
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Logic Model: Input ‚Üí Activities ‚Üí Output ‚Üí Outcome ‚Üí Impact")
    st.dataframe(logic_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô Logic Model"):
        with st.container(border=True):
            colA, colB, colC = st.columns(3)
            with colA:
                typ = st.selectbox("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó", ["Input","Activity","Output","Outcome","Impact"])
                desc = st.text_input("‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢/‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
                metric = st.text_input("‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î/metric (‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô, ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô)")
            with colB:
                unit = st.text_input("‡∏´‡∏ô‡πà‡∏ß‡∏¢", value="‡∏´‡∏ô‡πà‡∏ß‡∏¢", key="logic_unit")
                target = st.text_input("‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢", value="", key="logic_target")
            with colC:
                source = st.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="", key="logic_source")
                if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° Logic Item", type="primary"):
                    new_row = pd.DataFrame([{
                        "item_id": next_id("LG", logic_df, "item_id"),
                        "plan_id": plan["plan_id"],
                        "type": typ,
                        "description": desc,
                        "metric": metric,
                        "unit": unit,
                        "target": target,
                        "source": source
                    }])
                    st.session_state["logic_items"] = pd.concat([logic_df, new_row], ignore_index=True)
                    st.rerun()

# ----------------- Tab 3: Methods -----------------
with tab_method:
    set_current_tab("3. ‡∏£‡∏∞‡∏ö‡∏∏ Methods")
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Methods)")
    st.dataframe(methods_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏° Method"):
        with st.container(border=True):
            c1, c2, c3 = st.columns(3)
            with c1:
                mtype = st.selectbox("‡∏ä‡∏ô‡∏¥‡∏î", ["observe","interview","questionnaire","document"])
                tool_ref = st.text_input("‡∏£‡∏´‡∏±‡∏™/‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠", value="")
                sampling = st.text_input("‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", value="")
            with c2:
                questions = st.text_area("‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å")
                linked_issue = st.text_input("‡πÇ‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡∏£‡∏ß‡∏à", value="")
            with c3:
                data_source = st.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="", key="method_data_source")
                frequency = st.text_input("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà", value="‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß", key="method_frequency")
                if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° Method", type="primary", key="add_method_btn"):
                    new_row = pd.DataFrame([{
                        "method_id": next_id("MT", methods_df, "method_id"),
                        "plan_id": plan["plan_id"],
                        "type": mtype,
                        "tool_ref": tool_ref,
                        "sampling": sampling,
                        "questions": questions,
                        "linked_issue": linked_issue,
                        "data_source": data_source,
                        "frequency": frequency
                    }])
                    st.session_state["methods"] = pd.concat([methods_df, new_row], ignore_index=True)
                    st.rerun()
# ----------------- Tab 4: KPIs -----------------
with tab_kpi:
    set_current_tab("4. ‡∏£‡∏∞‡∏ö‡∏∏ KPIs")
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î (KPIs)")
    st.dataframe(kpis_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏° KPI ‡πÄ‡∏≠‡∏á"):
        with st.container(border=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                level = st.selectbox("‡∏£‡∏∞‡∏î‡∏±‡∏ö", ["output","outcome"])
                name = st.text_input("‡∏ä‡∏∑‡πà‡∏≠ KPI")
                formula = st.text_input("‡∏™‡∏π‡∏ï‡∏£/‡∏ô‡∏¥‡∏¢‡∏≤‡∏°")
            with col2:
                numerator = st.text_input("‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡πâ‡∏á (numerator)")
                denominator = st.text_input("‡∏ï‡∏±‡∏ß‡∏´‡∏≤‡∏£ (denominator)")
                unit = st.text_input("‡∏´‡∏ô‡πà‡∏ß‡∏¢", value="%", key="kpi_unit")
            with col3:
                baseline = st.text_input("Baseline", value="")
                target = st.text_input("Target", value="")
                freq = st.text_input("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà", value="‡∏£‡∏≤‡∏¢‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™")
                data_src = st.text_input("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="", key="kpi_data_source")
                quality = st.text_input("‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value="‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á/‡∏ó‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤", key="kpi_quality")
                if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° KPI", type="primary", key="add_kpi_btn"):
                    new_row = pd.DataFrame([{
                        "kpi_id": next_id("KPI", kpis_df, "kpi_id"),
                        "plan_id": plan["plan_id"],
                        "level": level,
                        "name": name,
                        "formula": formula,
                        "numerator": numerator,
                        "denominator": denominator,
                        "unit": unit,
                        "baseline": baseline,
                        "target": target,
                        "frequency": freq,
                        "data_source": data_src,
                        "quality_requirements": quality
                    }])
                    st.session_state["kpis"] = pd.concat([kpis_df, new_row], ignore_index=True)
                    st.rerun()

# ----------------- Tab 5: Risks -----------------
with tab_risk:
    set_current_tab("5. ‡∏£‡∏∞‡∏ö‡∏∏ Risks")
    st.subheader("‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Risks)")
    st.dataframe(risks_df, use_container_width=True, hide_index=True)
    with st.expander("‚ûï ‡πÄ‡∏û‡∏¥‡πà‡∏° Risk"):
        with st.container(border=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                desc = st.text_area("‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", key="risk_desc")
                category = st.text_input("‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà", key="risk_cat")
            with col2:
                likelihood = st.slider("‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏Å‡∏¥‡∏î (Likelihood)", 1, 5, 3)
                impact = st.slider("‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö (Impact)", 1, 5, 3)
                hypothesis = st.text_area("‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô/‡∏Ç‡πâ‡∏≠‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", key="risk_hypothesis")
            with col3:
                mitigation = st.text_area("‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£/‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏ö‡∏£‡∏£‡πÄ‡∏ó‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", key="risk_mitigation")
                if st.button("‡πÄ‡∏û‡∏¥‡πà‡∏° Risk", type="primary", key="add_risk_btn"):
                    new_row = pd.DataFrame([{
                        "risk_id": next_id("RSK", risks_df, "risk_id"),
                        "plan_id": plan["plan_id"],
                        "description": desc,
                        "category": category,
                        "likelihood": likelihood,
                        "impact": impact,
                        "mitigation": mitigation,
                        "hypothesis": hypothesis
                    }])
                    st.session_state["risks"] = pd.concat([risks_df, new_row], ignore_index=True)
                    st.rerun()
# ----------------- Tab 6: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ -----------------
with tab_issue:
    set_current_tab("6. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤")
    st.subheader("üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ (Findings Library Search)")
    
    # Load and process findings data
    uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Findings Library (CSV/Excel)", type=["csv", "xlsx", "xls"])
    findings_df = load_findings(uploaded=uploaded_file)
    
    if findings_df.empty:
        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï")
        template_data = create_excel_template()
        st.download_button(
            label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Template (Excel)",
            data=template_data,
            file_name="FindingsLibrary_Template.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.success(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÅ‡∏•‡πâ‡∏ß: {len(findings_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        vec, X = build_tfidf_index(findings_df)

        query_text = st.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:", value=st.session_state["issue_query_text"], key="search_query")
        top_k = st.slider("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£", 1, 20, 8)
        
        if st.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö", type="primary", key="search_btn"):
            if query_text:
                st.session_state["issue_query_text"] = query_text
                with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ {top_k} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö '{query_text}'..."):
                    results_df = search_candidates(query_text, findings_df, vec, X, top_k=top_k)
                    st.session_state.issue_results = results_df
            else:
                st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")

        if not st.session_state.issue_results.empty:
            st.markdown("#### ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°)")
            results_to_display = st.session_state.issue_results.copy()
            st.dataframe(results_to_display, use_container_width=True, hide_index=True)
            
            # Download link for results
            df_download_link(results_to_display, "Search_Results.csv", "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô CSV")

# ----------------- Tab 7: ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview) -----------------
with tab_preview:
    set_current_tab("7. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview)")
    st.subheader("üìù ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Preview)")
    
    st.markdown("#### 1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô & 6W2H")
    st.json(plan)
    
    st.markdown("#### 2. Logic Model")
    st.dataframe(logic_df, hide_index=True)
    
    st.markdown("#### 3. Methods")
    st.dataframe(methods_df, hide_index=True)

    st.markdown("#### 4. KPIs")
    st.dataframe(kpis_df, hide_index=True)

    st.markdown("#### 5. Risks")
    st.dataframe(risks_df, hide_index=True)

# ----------------- Tab 8: Assistant ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö -----------------
with tab_assist:
    set_current_tab("üí° Assistant ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
    st.subheader("üí° AI Assistant: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå")
    
    # Re-use the API Key callback function
    def save_api_key_assist():
        st.session_state.api_key_global = st.session_state.api_key_input_assist

    with st.container(border=True):
        st.markdown("üí° **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ API Key?** ‡∏Ñ‡∏•‡∏¥‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://playground.opentyphoon.ai/settings/api-key) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö key ‡∏ü‡∏£‡∏µ!")
        api_key_assist = st.text_input(
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ AI:", 
            type="password", 
            value=st.session_state.api_key_global,
            key="api_key_input_assist",
            on_change=save_api_key_assist
        )
        api_key_assist = st.session_state.api_key_global

        if st.button("üöÄ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô (Plan Data)", type="primary"):
            if not api_key_assist:
                st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            elif not plan.get("plan_title") and logic_df.empty:
                st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö 1 ‡πÅ‡∏•‡∏∞‡πÅ‡∏ó‡πá‡∏ö 2 ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
            else:
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥..."):
                    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI
                    plan_data = {k: v for k, v in plan.items() if v}
                    logic_str = logic_df.to_string(index=False)
                    kpi_str = kpis_df.to_string(index=False)
                    risk_str = risks_df.to_string(index=False)
                    
                    user_prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (Performance Audit) ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Audit Issues) ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô (Potential Findings) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™ (Likelihood 1-5)

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô:**
- Plan Detail: {plan_data}
- Logic Model: {logic_str}
- KPIs: {kpi_str}
- Risks: {risk_str}

**‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:**
1. **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Audit Issues):** ‡πÉ‡∏´‡πâ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô bullet points ‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á
2. **‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå (Potential Findings):** ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ú‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™ (1=‡∏ï‡πà‡∏≥, 5=‡∏™‡∏π‡∏á) ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:
   [‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö] (‡πÇ‡∏≠‡∏Å‡∏≤‡∏™: X/5)
3. **‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô:** ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö

**‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:**
<h4 style='color:blue;'>‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç</h4>
[bullet points]

<h4 style='color:blue;'>‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™)</h4>
[‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö] (‡πÇ‡∏≠‡∏Å‡∏≤‡∏™: X/5)
[‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö] (‡πÇ‡∏≠‡∏Å‡∏≤‡∏™: Y/5)

<h4 style='color:blue;'>‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô</h4>
[‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞]
"""
                    
                    try:
                        client = OpenAI(
                            api_key=api_key_assist,
                            base_url="https://api.opentyphoon.ai/v1"
                        )
                        response = client.chat.completions.create(
                            model="typhoon-v2.1-12b-instruct",
                            messages=[{"role": "user", "content": user_prompt}],
                            temperature=0.7,
                            max_tokens=2048,
                            top_p=0.9,
                        )
                        llm_output = response.choices[0].message.content
                        
                        # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                        parts = llm_output.split("<h4 style='color:blue;'>")
                        st.session_state["gen_issues"] = parts[1].split("</h4>")[1].strip() if len(parts) > 1 else ""
                        st.session_state["gen_findings"] = parts[2].split("</h4>")[1].strip() if len(parts) > 2 else ""
                        st.session_state["gen_report"] = parts[3].split("</h4>")[1].strip() if len(parts) > 3 else ""
                        
                        st.success("‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                        st.balloons()

                    except Exception as e:
                        import openai
                        error_type = type(e).__name__
                        if error_type in ["AuthenticationError", "APIError", "RateLimitError", "Timeout"]:
                            error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Rate Limit) ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"
                        else:
                            error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"
                             
                        st.error(error_message)
                        st.session_state["gen_issues"] = ""
                        st.session_state["gen_findings"] = ""
                        st.session_state["gen_report"] = ""

    st.markdown("<h4 style='color:blue;'>‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color: #f0f2f6; border: 1px solid #ccc; padding: 10px; border-radius: 5px; height: 200px; overflow-y: scroll;'>{st.session_state.get('gen_issues', '')}</div>", unsafe_allow_html=True)
    
    st.markdown("<h4 style='color:blue;'>‡∏Ç‡πâ‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏ö (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÇ‡∏≠‡∏Å‡∏≤‡∏™)</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color: #f0f2f6; border: 1px solid #ccc; padding: 10px; border-radius: 5px; height: 200px; overflow-y: scroll;'>{st.session_state.get('gen_findings', '')}</div>", unsafe_allow_html=True)

    st.markdown("<h4 style='color:blue;'>‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô</h4>", unsafe_allow_html=True)
    st.markdown(f"<div style='background-color: #f0f2f6; border: 1px solid #ccc; padding: 10px; border-radius: 5px; height: 200px; overflow-y: scroll;'>{st.session_state.get('gen_report', '')}</div>", unsafe_allow_html=True)


# ----------------- Tab 9: PA Chat (‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡πÄ) - FIX APPLIED HERE -----------------
with tab_chatbot:
    set_current_tab("üí¨ PA Chat (‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡πÄ)")
    st.subheader("üí¨ PA Chat - ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (RAG)")
    
    # --- START: FIX - ADD API KEY INPUT ---
    def save_api_key_chatbot():
        st.session_state.api_key_global = st.session_state.api_key_input_chatbot

    with st.expander("üîë ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key"): 
        st.markdown("üí° **‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ API Key?** ‡∏Ñ‡∏•‡∏¥‡∏Å [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://playground.opentyphoon.ai/settings/api-key) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö key ‡∏ü‡∏£‡∏µ!")
        st.text_input(
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ AI:", 
            type="password", 
            value=st.session_state.api_key_global,
            key="api_key_input_chatbot",
            on_change=save_api_key_chatbot
        )
    # --- END: FIX - ADD API KEY INPUT ---
    
    # RAG Upload Section
    uploaded_files = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ AI (PDF, TXT, CSV) - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î‡πÅ‡∏≠‡∏õ",
        type=['pdf', 'txt', 'csv'],
        accept_multiple_files=True
    )
    
    # Process uploaded files if any
    current_uploaded_file_names = {f.name for f in uploaded_files}
    if uploaded_files and st.session_state.get('last_uploaded_files') != current_uploaded_file_names:
        # Clear existing uploaded context before processing new files to prevent stacking
        st.session_state.doc_context_uploaded = ""
        st.session_state.doc_context_uploaded, _ = process_documents(
            uploaded_files, 
            'uploaded', 
            MAX_CHARS_LIMIT, 
            len(st.session_state.doc_context_local)
        )
        st.session_state.last_uploaded_files = current_uploaded_file_names
        # Clear chat history when new docs are uploaded
        st.session_state.chatbot_messages = [
            {"role": "assistant", "content": "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏â‡∏ö‡∏±‡∏ö‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö"}
        ]
        st.rerun()
    elif not uploaded_files:
        # Clear uploaded context if files are removed
        if st.session_state.doc_context_uploaded:
             st.session_state.doc_context_uploaded = ""
             st.session_state.last_uploaded_files = set()
             st.session_state.chatbot_messages.append({"role": "assistant", "content": "‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö"})
             st.rerun()

    # Display total context length
    doc_context_len = len(st.session_state.doc_context_local) + len(st.session_state.doc_context_uploaded)
    st.info(f"üíæ ‡πÇ‡∏´‡∏•‡∏î‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏£‡∏ß‡∏°: {doc_context_len:,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {MAX_CHARS_LIMIT:,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)")

    # 1. FIX: Use a fixed-height container for messages (This pushes the input below the container)
    chat_container = st.container(height=500, border=True)

    with chat_container:
        # 2. FIX: Display all messages *inside* the container, *before* the input logic runs.
        for message in st.session_state.chatbot_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # 3. Chat Input (This will be rendered immediately after the container)
    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...", key="chat_input_main"):
        # Append user message to history
        st.session_state.chatbot_messages.append({"role": "user", "content": prompt})
        
        # Display the user message immediately in the container for this run
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                
                api_key = st.session_state.api_key_global
                if not api_key:
                    error_message = "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡∏î‡∏π‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö 1, 8 ‡∏´‡∏£‡∏∑‡∏≠ 9)"
                    st.error(error_message)
                    st.session_state.chatbot_messages.append({"role": "assistant", "content": error_message})
                    message_placeholder.markdown(error_message)
                    # We stop the streaming logic here, but let the app continue for the user to fix the key.
                else:
                    try:
                        # Prepare RAG context
                        doc_context = st.session_state.doc_context_local + st.session_state.doc_context_uploaded
                        
                        client = OpenAI(
                            api_key=api_key,
                            base_url="https://api.opentyphoon.ai/v1"
                        )
                        
                        system_prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (Performance Audit) ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô '‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô' ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏¢‡∏∂‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ \"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ú‡∏°\"

---
**‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏¢‡πÉ‡∏ô:**
{doc_context}
---

‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡∏ô‡∏µ‡πâ ‡∏à‡∏á‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
"""
                        
                        messages_for_api = [
                            {"role": "system", "content": system_prompt}
                        ]
                        # Add chat history (including the newly added user message)
                        for msg in st.session_state.chatbot_messages[-10:]:
                            messages_for_api.append(msg)

                        response_stream = client.chat.completions.create(
                            model="typhoon-v2.1-12b-instruct",
                            messages=messages_for_api,
                            temperature=0.5,
                            max_tokens=3072,
                            stream=True
                        )
                        
                        # FIX: Stream the response directly into the placeholder in the container
                        response = message_placeholder.write_stream(response_stream)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": response})

                    except Exception as e:
                        import openai
                        error_type = type(e).__name__
                        if error_type in ["AuthenticationError", "APIError", "RateLimitError", "Timeout"]:
                            error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Rate Limit) ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"
                        else:
                            error_message = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ({error_type}) ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: {e}"

                        st.error(error_message)
                        st.session_state.chatbot_messages.append({"role": "assistant", "content": error_message})
                        message_placeholder.markdown(error_message)
# ----------------- END: Tab 9 -----------------
